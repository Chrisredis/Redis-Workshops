{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Z5knSKZrQN_i"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/Redislabs-Solution-Architects/Redis-Workshops/blob/main/02-Vector_Similarity_Search/02.01_RedisVL.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tRlp93K0C1q8"
   },
   "source": [
    "# Vector Search with RedisVL\n",
    "\n",
    "[Always-on demo](https://antonum-redis-vss-streamlit-streamlit-app-p4z5th.streamlit.app/)\n",
    "\n",
    "![Redis](https://redis.io/wp-content/uploads/2024/04/Logotype.svg?auto=webp&quality=85,75&width=120)\n",
    "\n",
    "This notebook generates vector embeddings using pre-trained `sentence-transformers/all-MiniLM-L6-v2` model from HuggingFace, loads them to Redis and runs Vector Similarity search against Redis database using the Redis Vector Library ([RedisVL](https://www.redisvl.com/)) for Python.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "H-9YfABV3_1z",
    "outputId": "fb4ed8ab-4e63-4115-a0e7-7bfd058941b3"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.0/61.0 kB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m157.1/157.1 kB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.3/18.3 MB\u001b[0m \u001b[31m29.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m278.7/278.7 kB\u001b[0m \u001b[31m17.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m62.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m60.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m40.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m12.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m74.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "thinc 8.3.6 requires numpy<3.0.0,>=2.0.0, but you have numpy 1.26.4 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "# Install Redis client and Hugging Face sentence transformers\n",
    "!pip install -q sentence_transformers redisvl\n",
    "# Fix NumPy compatibility issue\n",
    "!pip uninstall -y numpy pandas\n",
    "!pip install numpy pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8Nkcsc8ceWpS"
   },
   "source": [
    "### Install Redis Stack locally\n",
    "\n",
    "This installs the Redis Stack database for local usage if you cannot or do not want to create a Redis Cloud database, and it installs the `redis-cli` that will be used for checking database connectivity, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nofqstGujZSE",
    "outputId": "8c71deb5-f45e-49a6-e04a-35abe7305d51"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "deb [signed-by=/usr/share/keyrings/redis-archive-keyring.gpg] https://packages.redis.io/deb jammy main\n",
      "Starting redis-stack-server, database path /var/lib/redis-stack\n"
     ]
    }
   ],
   "source": [
    "%%sh\n",
    "# curl -fsSL https://packages.redis.io/gpg | sudo gpg --dearmor -o /usr/share/keyrings/redis-archive-keyring.gpg  # COMMENTED OUT - Using Redis Cloud by default\n",
    "echo \"deb [signed-by=/usr/share/keyrings/redis-archive-keyring.gpg] https://packages.redis.io/deb $(lsb_release -cs) main\" | sudo tee /etc/apt/sources.list.d/redis.list\n",
    "sudo apt-get update  > /dev/null 2>&1\n",
    "# # sudo apt-get install redis-stack-server  > /dev/null 2>&1  # COMMENTED OUT - Using Redis Cloud by default  # COMMENTED OUT - Using Redis Cloud by default\n",
    "# redis-stack-server --daemonize yes  # COMMENTED OUT - Using Redis Cloud by default\n",
    "\n",
    "print(\"✅ Using Redis Cloud - no local installation needed!\")\n",
    ""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YhS6htjOCxr_"
   },
   "source": [
    "### Setup Redis connection\n",
    "***Note - Replace Redis connection values if using a Redis Cloud instance!***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2UxA0cSkBYgo",
    "outputId": "3ec52657-d7eb-4d99-bf58-4798641dcd9b"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "PONG\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Redis Cloud Configuration (Default)\n",
    "# Using Redis Cloud for persistent data storage\n",
    "import redis\n",
    "REDIS_HOST = os.getenv(\"REDIS_HOST\", \"redis-15306.c329.us-east4-1.gce.redns.redis-cloud.com\")\n",
    "REDIS_PORT = os.getenv(\"REDIS_PORT\", \"15306\")\n",
    "REDIS_PASSWORD = os.getenv(\"REDIS_PASSWORD\", \"ftswOcgMB8dLCnjbKMMDBg3DNnpi1KO5\")\n",
    "REDIS_USERNAME = os.getenv(\"REDIS_USERNAME\", \"default\")\n",
    "# Replace values above with your own if using Redis Cloud instance\n",
    "# REDIS_HOST=\"redis-12110.c82.us-east-1-2.ec2.cloud.redislabs.com\"\n",
    "# REDIS_PORT=12110\n",
    "# REDIS_PASSWORD=\"pobhBJP7Psicp2gV0iqa2ZOc1WdXXXXX\"\n",
    "\n",
    "# Shortcut for redis-cli $REDIS_CONN command\n",
    "if REDIS_PASSWORD!=\"\":\n",
    "  os.environ[\"REDIS_CONN\"]=f\"-h {REDIS_HOST} -p {REDIS_PORT} -a {REDIS_PASSWORD} --no-auth-warning\"\n",
    "else:\n",
    "  os.environ[\"REDIS_CONN\"]=f\"-h {REDIS_HOST} -p {REDIS_PORT}\"\n",
    "\n",
    "# If SSL is enabled on the endpoint, use rediss:// as the URL prefix\n",
    "REDIS_URL = f\"redis://:{REDIS_PASSWORD}@{REDIS_HOST}:{REDIS_PORT}\"\n",
    "\n",
    "# Test Redis connection\n",
    "!redis-cli $REDIS_CONN PING\n",
    "print(f\"🔗 Connecting to Redis Cloud: {REDIS_HOST}:{REDIS_PORT}\")\n",
    ""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qTmrdlO2G_dP"
   },
   "source": [
    "### Initialize Embedding Model\n",
    "Import a [RedisVL vectorizer](https://www.redisvl.com/user_guide/vectorizers_04.html#vectorizers) to generate text embeddings. For this lab, we are using the Hugging Face Text Vectorizer and selecting the `sentence-transformers/all-MiniLM-L6-v2` [model](https://huggingface.co/sentence-transformers/all-MiniLM-L6-v2)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 391
    },
    "id": "Sb3fH3iM8_Nz",
    "outputId": "cd51931a-1858-4203-ea27-c34a7d74fb49"
   },
   "outputs": [
    {
     "output_type": "error",
     "ename": "ValueError",
     "evalue": "numpy.dtype size changed, may indicate binary incompatibility. Expected 96 from C header, got 88 from PyObject",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-d7a8c45182e7>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mredisvl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvectorize\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mHFTextVectorizer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     35\u001b[0m     ) from _err\n\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m from pandas._config import (\n\u001b[0m\u001b[1;32m     38\u001b[0m     \u001b[0mget_option\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m     \u001b[0mset_option\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/_config/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0;34m\"warn_copy_on_write\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m ]\n\u001b[0;32m---> 20\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mpandas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_config\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpandas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_config\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdates\u001b[0m  \u001b[0;31m# pyright: ignore[reportUnusedImport]  # noqa: F401\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m from pandas._config.config import (\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/_config/config.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     66\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mwarnings\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 68\u001b[0;31m from pandas._typing import (\n\u001b[0m\u001b[1;32m     69\u001b[0m     \u001b[0mF\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m     \u001b[0mT\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/_typing.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    196\u001b[0m     \u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    197\u001b[0m     \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 198\u001b[0;31m     \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGenerator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    199\u001b[0m     \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBitGenerator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m     \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRandomState\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/numpy/__init__.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(attr)\u001b[0m\n\u001b[1;32m    335\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    336\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__dir__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 337\u001b[0;31m         \u001b[0mpublic_symbols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mglobals\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'testing'\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    338\u001b[0m         public_symbols -= {\n\u001b[1;32m    339\u001b[0m             \u001b[0;34m\"core\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"matrixlib\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/numpy/random/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    178\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    179\u001b[0m \u001b[0;31m# add these for module-freeze analysis (like PyInstaller)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 180\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m_pickle\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    181\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m_common\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    182\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m_bounded_integers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/numpy/random/_pickle.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mmtrand\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mRandomState\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0m_philox\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mPhilox\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0m_pcg64\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mPCG64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mPCG64DXSM\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0m_sfc64\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSFC64\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mnumpy/random/mtrand.pyx\u001b[0m in \u001b[0;36minit numpy.random.mtrand\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: numpy.dtype size changed, may indicate binary incompatibility. Expected 96 from C header, got 88 from PyObject"
     ]
    }
   ],
   "source": [
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "from redisvl.utils.vectorize import HFTextVectorizer\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "tqdm.pandas()\n",
    "# Create a vectorizer\n",
    "# Choose your model from the huggingface website\n",
    "hf = HFTextVectorizer(model=\"sentence-transformers/all-MiniLM-L6-v2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "B1JCI2e_KTQj"
   },
   "outputs": [],
   "source": [
    "# Embed a sentence\n",
    "test = hf.embed(\"This is a test sentence.\")\n",
    "\n",
    "# Uncomment to see vector embedding output\n",
    "# test[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Gz5QOrxWCFd8"
   },
   "source": [
    "### Embedding generation model\n",
    "\n",
    "Here we are using `sentence-transformers/all-MiniLM-L6-v2` from HuggingFace. https://huggingface.co/sentence-transformers/all-MiniLM-L6-v2\n",
    "\n",
    "***Note - the following block is not needed for this lab, as we already specified our embedding model above with RedisVL.***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QEXNz8-TCEfA"
   },
   "outputs": [],
   "source": [
    "# from sentence_transformers import SentenceTransformer\n",
    "# model = SentenceTransformer('sentence-transformers/all-MiniLM-L6-v2')\n",
    "# test=model.encode(\"This is a test sentence.\")\n",
    "# test[:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hJBWKmOykJRT"
   },
   "source": [
    "### Download data to vectorize and store in Redis\n",
    "Download 12k+ tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Yw4PTJI_Hsdn"
   },
   "outputs": [],
   "source": [
    "!wget https://raw.githubusercontent.com/antonum/Redis-VSS-Streamlit/main/Labelled_Tweets.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pXpRVr82G_dQ"
   },
   "source": [
    "***Note - make sure to uncomment the `df=df.head(100)` line below if you are using the Free 30MB Redis Cloud database!***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EFy8uuJH6nh3"
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('Labelled_Tweets.csv').drop(columns=['created_at','score'])\n",
    "# df=df.head(100) #trim dataframe to fit results into 30MB Redis database\n",
    "df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xTslHIdJkZJh"
   },
   "source": [
    "### Generate Embeddings\n",
    "\n",
    "Generate vector embeddings within the dataframe. This step can take 2-3 minutes on GPU runtime for all 12k records."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hr4O80YemL_z"
   },
   "outputs": [],
   "source": [
    "def texts_to_embeddings(texts):\n",
    "  return [np.array(embedding, dtype=np.float32).tobytes() for embedding in hf.embed_many(texts)]\n",
    "\n",
    "# Generate vector embeddings\n",
    "df[\"text_embedding\"] = texts_to_embeddings(df[\"full_text\"].tolist())\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "E101rw12ksSa"
   },
   "source": [
    "### Define RediSearch Schema\n",
    "[Define the RediSearch schema](https://redis.io/docs/latest/develop/interact/search-and-query/basic-constructs/schema-definition/) using the [RedisVL syntax](https://redis.io/docs/latest/integrate/redisvl/api/schema/) with the following details:\n",
    "- Key Type: `Hash`\n",
    "- Key Prefix: `tweet:`\n",
    "- Indexed Fields:\n",
    "  - `text`: Full Text\n",
    "  - `text_embedding`: Vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "36p5NNnUC10d"
   },
   "outputs": [],
   "source": [
    "schema = {\n",
    "    \"index\": {\n",
    "        \"name\": \"tweet:idx\",\n",
    "        \"prefix\": \"tweet:\",\n",
    "        \"storage_type\": \"hash\", # default setting -- HASH\n",
    "    },\n",
    "    \"fields\": [\n",
    "        {   \"name\": \"full_text\",\n",
    "            \"type\": \"text\",\n",
    "            \"attrs\": {\n",
    "                \"no_stem\": False,\n",
    "                \"sortable\": False\n",
    "            }\n",
    "        },\n",
    "        {\n",
    "            \"name\": \"text_embedding\",\n",
    "            \"type\": \"vector\",\n",
    "            \"attrs\": {\n",
    "                \"dims\": 384,\n",
    "                \"distance_metric\": \"cosine\",\n",
    "                \"algorithm\": \"HNSW\",\n",
    "                \"datatype\": \"float32\"\n",
    "            }\n",
    "\n",
    "        }\n",
    "    ],\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Bpz-BT2qBqsg"
   },
   "source": [
    "### Create index and load data to Redis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "i3l3Jm1KVeQq"
   },
   "outputs": [],
   "source": [
    "# Clear Redis database (optional)\n",
    "# redis.flushdb()\n",
    "\n",
    "from redisvl.index import SearchIndex\n",
    "\n",
    "index = SearchIndex.from_dict(schema)\n",
    "\n",
    "index.connect(REDIS_URL)\n",
    "\n",
    "index.create(overwrite=True)\n",
    "\n",
    "keys = index.load(df.to_dict('records'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uXhqWfKgJqcv"
   },
   "outputs": [],
   "source": [
    "# Check how the data is stored in Redis\n",
    "# !redis-cli $REDIS_CONN keys \"*\"\n",
    "# !redis-cli $REDIS_CONN hgetall \"tweet::c4b63c9494194d4ea65b7e265bcd2d5f\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ovtxchAGEG9t"
   },
   "source": [
    "## Query the database\n",
    "\n",
    "[Alway-on Streamlit app](https://antonum-redis-vss-streamlit-streamlit-app-p4z5th.streamlit.app/)\n",
    "\n",
    "\n",
    "Try queries like:\n",
    "“Oil”, “Oil Reserves”, “Fossil fuels”\n",
    "\n",
    "Lexical Full Text search quickly runs out of matches\n",
    "\n",
    "Vector search continues to discover relevant tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "koOnsz_NqUje"
   },
   "outputs": [],
   "source": [
    "user_query=\"oil price\"\n",
    "# Queries to try: \"oil reserve\", \"fossil fuels\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tCY8U8elLZkW"
   },
   "outputs": [],
   "source": [
    "# Using Full Text Index\n",
    "from redisvl.query import FilterQuery\n",
    "from redisvl.query.filter import Text\n",
    "\n",
    "# Exact match filter -- document must contain the exact word doctor\n",
    "text_filter = Text(\"full_text\") == user_query\n",
    "\n",
    "filter_query = FilterQuery(\n",
    "    return_fields=[\"full_text\"],\n",
    "    filter_expression=text_filter\n",
    ")\n",
    "\n",
    "results = index.query(filter_query)\n",
    "\n",
    "pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gBUXk1glS3fZ"
   },
   "outputs": [],
   "source": [
    "# Using Vector Index\n",
    "from redisvl.query import VectorQuery\n",
    "# from jupyterutils import result_print\n",
    "\n",
    "query = VectorQuery(\n",
    "    vector=hf.embed(user_query),\n",
    "    vector_field_name=\"text_embedding\",\n",
    "    return_fields=[\"full_text\", \"vector_distance\"],\n",
    "    num_results=10\n",
    ")\n",
    "results = index.query(query)\n",
    "pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tfChZv9ZG_dR"
   },
   "source": [
    "#### Cleanup\n",
    "(Optional) Delete all keys and indexes from the database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KNxp8I95G_dR"
   },
   "outputs": [],
   "source": [
    "###-- FLUSHDB will wipe out the entire database!!! Use with caution --###\n",
    "# !redis-cli $REDIS_CONN flushdb"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}